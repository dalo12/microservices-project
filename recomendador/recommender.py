# -*- coding: utf-8 -*-
"""[TADW 2025] - Sistemas de recomendación

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ieC9aMhiK0u0VfG8S2e63Q1dut-cdYEi

# Tópicos Avanzados de Desarrollo Web - Sistemas de recomendación

![header_logo-8d96d7078a3d63f9f31d92282fd67cf4.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMUAAAArCAMAAAD/qLwwAAAANlBMVEUAAABGMCBGMCBGMCBGMCBGMCBGMCBGMCBGMCBGMCBGMCBGMCBGMCBGMCBGMCD///9GMCBGMCAjQGcfAAAAEXRSTlMAgEDAENDgYKDwMCBQsJAAcLXPCcoAAASgSURBVHhe7ZjZjq0qEEApCijmlv//2YsiIKB2Tu4ZspOul7YXiCwGyw37Y+GI/e4gRHvHv/6cBcffbgEp8X9q8WPxY/Fj8WPxY+G2iKg3V/5xTcADds6+wYJipmAvFoJztytpmeB8EmBKyeAmhlu3IA8MY5suYsYqkBgseDxr24uF00YT5x4k7hjgdCAlgXNOubh4vGHRGlG+WfCUgImQckCplGoY6A4x9dBFb669dQuBvTa6akGqNegVNQsRJK/NgfGZvGGroD6eSz1YyFQtrMoXUgOE/QLFKSGP8QYAfZQfuNZW+sQoikWpLuOJjS0WlC+6vqTTQkjNeliT9e5xv+hjqC8WkJIkt3NnUkJexytfl0vMDidlPFeJBTvTOc+ieFro7OA6loeFU3ZYoYoXi1AkuoZlL1jSgJGaRTRpO6lMSXdVmUoBZQnRsE0piSonxXVxmcNClOq9EdotcJvT1WFBct7Rij1jCCMVyleLLkEphaFOMqK48QvW57/UJarUUUKpNVgeELKFVWwKDLuF4gunZ2zcREFXi4SVlV4PPdjK2F6pL1tolmPutICRq5SyRYTZwqeMvGQLl4+YwkydaRZ+7N7QAyyjObgVC1v1W+hm4S+UAERWtmyO3UJvbAnlnnCghcpmcenFNGOxFa5zsaU0NWrbisIl6920g3B0bQlNT9isGIrFsKDmiaS7ZByKRaibfFg8vKys4EYLK1eLCLdyDOAX8FYtQiXlFTotHn8FjlNUqVjIZGY/LNJHitT+asHxrlu3OMNfwD1f9C4rHEO2UkeAMtWAwxmfvqPOTI/A/4nFGqWUsAOpv7VgvNXX/O9bICzB22cRYoSNC8bfLUq4LajigfZ5d9t7C/v/LGAU7enXRFvBi0UcM4XwsXxIfd2+jMzv2N0wW4i60dcRlm7NFzKp2909BpfpSKWaZgm7t6LsahHoCRu3UD1bMDO+aTtOjq0WuL5pzcOLeWPM4/r8bBG31cKIJxxopYsFLlnPcS7sPEVULEqKXrOeA6CJhpsvI6sA2F0e8fiIKSxULRbbsjFkMut20d98gaQpkZR6XIlxs3mADHCUK+QJC+NmGhcLkdavQb1YuJRBzdTToB9EjZMkTtsoxVUCGECX60HInjGEkXo55Is2mGF6ObndTQ6wWtAoLeRpAeWGZYZjX1SktvqLNeppoTn2giUN1NgbC2GyhugSbRtv/UaZTBXP5dJeJIzOFqUV3W/oLwdejgN8VNfTA61Fl+Aql7xgZ2j8HTta9EcaOjwc5GusKyWWjnidkvQHF3uTrUTstf2Z9Shj9Kzx+NWU2tFMt2DQ5kjEMiov2MkoTgrKz1mva+SQiCqlNi+0M3UyLVjWkwbKxOQwiPtfw1vupnRtRT+cqgFUt6AicIKgCnnHJAN4D1ppsebu9WxGUZ/QypBXK6hDXcKAuP2OSsqzZ4saggMA9Xl4x5YANs5eQxAgYoChmoXQlwJzG/jh/C6WVTjfgHFrp2q4WCBnHxPVQrmZKvd5FoEmyCX7PAuuJijp4yzW0z4d2CdaCETXCMcgPtCiH+WXU3tinxY9X3DQR/K27APj6z98TUeQjcpBPAAAAABJRU5ErkJggg==)

En este ejemplo trabajaremos a partir de un dataset de libros de la página [Goodreads](http://www.goodreads.com), **que ha sido previamente limpiado y adaptado**, para preparar algunos modelos de recomendación.

## Importando librerías y cargando los datos
"""

import pandas as pd
import numpy as np
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity

import warnings
warnings.filterwarnings('ignore')

"""Comenzamos por cargar en un Pandas DataFrame el dataset, que ya ha sido preparado y puesto a disposición en formato CSV en GitHub."""

books = pd.read_csv("https://raw.githubusercontent.com/hfmartinez85/datasets/main/tadw/books-clean.csv")

"""Exploremos el dataset:"""

books

"""## Recomendador simple

El **Recomendador Simple** ofrece recomendaciones generalizadas a cada usuario basadas en la popularidad del libro y (a veces) del género. La idea básica detrás de este recomendador es que los libros que son más populares y más aclamados por la crítica tendrán una mayor probabilidad de ser del agrado de la audiencia promedio. **Este modelo no da recomendaciones personalizadas en base al usuario**.

La implementación de este modelo es, en esencia, trivial. Todo lo que tenemos que hacer es clasificar nuestros libros según las calificaciones y la popularidad y mostrar los mejores libros de nuestra lista. Como paso adicional, podemos pasar un parámetro de género para obtener los mejores libros de un género en particular.

Sin embargo, nos apoyaremos en una **fórmula que diluya el sesgo** que pueda haber en libros con pocas calificaciones.

Usaremos la fórmula del rating ponderado de IMDB:

> Weighted Rating (WR) = $(\frac{v}{v + m} . R) + (\frac{m}{v + m} . C)$

Donde:
* *v* es el número de ratings para el libro
* *m* es el mínimo número deseable de ratings para ser considerado
* *R* es el rating promedio del libro
* *C* es el rating promedio en todo el dataset

¿Qué tiene en cuenta esta fórmula?

1.   **Votos significativos**: La fórmula ajusta la calificación promedio (R) basándose en el número de votos (v). Cuanto mayor sea v, más peso tiene R en el resultado.
2.   **Calificación general**: En ítems con menos votos, la fórmula aplica una ponderación hacia C, la calificación promedio general, ayudando a evitar que calificaciones extremas dominen el ranking.
3.   **Balanceo**: Si un ítem tiene muchos votos (es decir, v es alto), su promedio será menos afectado por C. En cambio, si tiene pocos votos, C tiene mayor peso en la calificación final.

El siguiente paso es determinar un valor apropiado para *m*, las clasificaciones mínimas requeridas para tener en cuenta al libro. Probaremos con el **percentil 95**, es decir, el número que sirve de límite inferior al 5% de libros con mayor cantidad de calificaciones.
"""

print("Percentil 95 =", round(books['ratings_count'].quantile(0.95)))

v = books['ratings_count']
m = books['ratings_count'].quantile(0.95)
R = books['average_rating']
C = books['average_rating'].mean()
W = (R*v + C*m) / (v + m)

books['weighted_rating'] = W

qualified = books.sort_values('weighted_rating', ascending=False).head(250)

"""Exploremos los 15 mejores libros:"""

qualified[['title', 'authors', 'average_rating', 'ratings_count', 'weighted_rating', 'genres']].head(15)

"""Cómo podemos ver, hay libros con mejores promedios de calificación que los que encabezan la lista, pero que por tener menor cantidad de *ratings* son retrasados en la lista.

Tambien podemos apreciar que los libros de Harry Potter de J.K. Rowling se encuentran en la parte superior de nuestra tabla, que son justamente los que mayor cantidad de calificaciones tienen.

Podemos sospechar que hay algún desbalance en la distribución de géneros de nuestro dataset. Podríamos realizar un análisis exploratorio para entender mejor esta característica:
"""

# En primer lugar, separamos los géneros en listas
genres_list = books['genres'].str.split(', ')

# Reemplazamos valores nulos en genres_list con listas vacías
genres_list = genres_list.apply(lambda x: x if isinstance(x, list) else [])

# Creamos una lista única de todos los géneros
all_genres = sum(genres_list, [])

# Contamos la frecuencia de cada género
genre_counts = pd.DataFrame(Counter(all_genres).items(), columns=['genre', 'count']).sort_values(by='count', ascending=False)

# Visualizamos los resultados en un gráfico de barras
plt.figure(figsize=(10, 6))
plt.bar(genre_counts['genre'], genre_counts['count'], color='skyblue')
plt.xlabel('Género')
plt.ylabel('Frecuencia')
plt.title('Distribución de Géneros')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()  # Ajuste para evitar que se superpongan las etiquetas
plt.show()

"""Veamos ahora la distribución con un gráfico de torta:"""

# Filtramos los 15 géneros más frecuentes
top_genres = genre_counts.head(15)

# Sumamos el resto de los géneros en una única opción ("Others")
others_count = genre_counts['count'][15:].sum()

# Creamos un nuevo DataFrame para "Others"
others_df = pd.DataFrame({'genre': ['Others'], 'count': [others_count]})

# Concatenamos los dos DataFrames
final_genres = pd.concat([top_genres, others_df], ignore_index=True)

# Visualizamos el resultado en un gráfico de torta
plt.figure(figsize=(10, 6))
plt.pie(final_genres['count'], labels=final_genres['genre'], autopct='%1.1f%%', startangle=90)
plt.axis('equal')  # Para que el gráfico sea un círculo
plt.title('Distribución de Géneros (Top 15 + Others)')
plt.show()

"""En función de este desbalance que se puede observar, tal vez sea útil poder mejorar el recomendador para que opere dentro de un mismo género.

Construyamos entonces una función que permita crear rankings para géneros particulares. Para esto, relajaremos las condiciones predeterminadas al percentil 85 en lugar del 95.

### Mejores libros por género
"""

print("Percentil 85 =", round(books['ratings_count'].quantile(0.85)))

def build_chart(genre, percentile=0.85):
    # Chequeamos que el libro pertenezca al género recibido, ignorando valores nulos
    qualified = books[books['genres'].notna() & books['genres'].str.lower().str.contains(genre.lower())]

    # Verificamos que haya libros calificados
    if qualified.empty:
        return "No hay libros calificados en este género."

    v = qualified['ratings_count']
    m = qualified['ratings_count'].quantile(percentile)
    R = qualified['average_rating']
    C = qualified['average_rating'].mean()
    qualified['weighted_rating'] = (R * v + C * m) / (v + m)

    qualified.sort_values('weighted_rating', ascending=False, inplace=True)
    return qualified

"""Probemos la función, armando el top de libros de biografías, que tiene una representación más acotada en el dataset:"""

genre = 'Biography'
build_chart(genre).head(15)

"""Ahora estamos en condiciones de adaptar el recomendador para tener en cuenta un género en particular.

Sobre cómo dar un resultado final, en caso de que se espere un único registro, se pueden seguir varias estrategias. Por ejemplo, podemos entregar el mejor puntuado, o bien devolver uno al azar entre los primeros ***n*** mejores resultados del ranking.

## Recomendadores basados en contenido (content-based)

El recomendador que construimos en la sección anterior sufre de algunas limitaciones severas. Por un lado, da la misma recomendación a todos, independientemente del gusto personal del usuario.

Por ejemplo, consideremos a una persona que le gustó *The Fault in Our Stars* (Bajo la misma estrella) y *Twilight* (Crepúsculo). Una inferencia que podemos obtener es que a la persona le gustan los libros románticos. Pero incluso si accediera a la tabla de romances, no encontraría estas como las principales recomendaciones.

Para personalizar más nuestras recomendaciones, crearemos un motor que calcule la similitud entre ítems en función de ciertas métricas, y sugiera opciones que sean más parecidas a un libro en particular según los gustos de un usuario. Dado que usaremos metadatos (o contenido) de libros para construir este motor, esto también se conoce como **filtrado basado en contenido.**

![](https://miro.medium.com/max/828/1*1b-yMSGZ1HfxvHiJCiPV7Q.png)

**Como decisión de diseño, a partir de los atributos con los que contamos, construiremos este recomendador basado en el *título*, *autores* y *géneros* del libro.**

Estos son los pasos que seguiremos:

1. **Eliminar espacios y convertir a minúsculas** los nombres de los autores. De esta forma, nuestro motor no confundirá entre **Stephen Covey** y **Stephen King**.
2. Combinar en un mismo string **título**, **géneros** y **autores**.
3. Luego usaremos **count vectorizer** para crear una matriz de conteo.

Finalmente, calculamos las similitudes por coseno, y devolvemos los libros que son más similares.
"""

# Tranformación de autores
books['authors_clean'] = books['authors'].apply(lambda x: ', '.join(str.lower(i.replace(" ", "")) for i in x.split(', ')))

# Veamos el resultado parcial
books['authors_clean'].head()

# Combinamos en un mismo string los títulos, autores y géneros
books['soup'] = books.apply(lambda x: ' '.join([str(x['title']), str(x['authors_clean'] or ''), str(x['genres'] or '')]), axis=1)

# Exploremos el resultado
books.soup.head()

count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0.0, stop_words='english')
count_matrix = count.fit_transform(books['soup'])

"""Explicación del código anterior:

1. **`count = CountVectorizer(...)`**  
   Aquí estamos creando una instancia de `CountVectorizer`, una herramienta de la biblioteca `sklearn.feature_extraction.text`. `CountVectorizer` convierte texto en una **matriz de conteo de términos**, lo cual es útil para análisis de texto y clasificación. Veamos cada parámetro:

   - **`analyzer='word'`**: especifica que queremos analizar el texto por palabras, en lugar de por caracteres o subpalabras.
   - **`ngram_range=(1, 2)`**: indica que queremos considerar tanto palabras individuales (unigramas) como combinaciones de dos palabras consecutivas (bigramas).
   - **`min_df=0`**: establece que todas las palabras o bigramas, sin importar su frecuencia mínima, se incluyan en la matriz de conteo.
   - **`stop_words='english'`**: excluye las palabras comunes en inglés (como "the", "is", "and"), que suelen aportar poco al análisis.

2. **`count_matrix = count.fit_transform(books['soup'])`**  
   Aquí, `count.fit_transform()` aplica `CountVectorizer` a la columna `'soup'` del DataFrame `books`.

   - `fit_transform()` realiza dos tareas: primero, ajusta el modelo (`fit`), aprendiendo el vocabulario y los términos del texto, y luego convierte el texto en una **matriz esparsa** de conteo de términos (`transform`).
   
   Esta matriz `count_matrix` tiene cada fila representando un documento y cada columna representando una palabra o bigrama, con valores que indican la frecuencia de cada término en cada documento.

Así se vería un ejemplo de `count_matrix`:

|         | adventure | book | fiction | fantastic | mystery | mystery book | science | thrilling | thrilling mystery |
|---------|-----------|------|---------|-----------|---------|--------------|---------|-----------|--------------------|
| **0**   | 0         | 1    | 0       | 0         | 1       | 1            | 0       | 1         | 1                  |
| **1**   | 1         | 0    | 1       | 1         | 0       | 0            | 1       | 0         | 0                  |
| **2**   | 1         | 1    | 0       | 0         | 1       | 0            | 0       | 0         | 0                  |

### Similitud por coseno

Usaremos la similitud del coseno para medir la similitud entre dos libros.

Para entender el concepto, primero veamos un ejemplo simple, con dos vectores de dos dimensiones:
"""

# Creamos dos vectores de ejemplo
vector1 = np.array([0.7, 0.3])
vector2 = np.array([0.5, 0.5])

# Calculamos el producto punto
dot_product = np.dot(vector1, vector2)

# Calculamos las normas (magnitudes) de los vectores
norm_vector1 = np.linalg.norm(vector1)
norm_vector2 = np.linalg.norm(vector2)

# Calculamos la similitud por coseno
cosine_sim = dot_product / (norm_vector1 * norm_vector2)

# Veamos el resultado gráficamente
plt.figure(figsize=(6, 4))
plt.quiver([0, 0], [0, 0], [vector1[0], vector2[0]], [vector1[1], vector2[1]], angles='xy', scale_units='xy', scale=1)
plt.xlim(-1, 1)
plt.ylim(-1, 1)
plt.title("Similitud por Coseno")
plt.xlabel("Componente 1")
plt.ylabel("Componente 2")
plt.grid(True)
plt.show()

"""La similitud por coseno es una medida de similaridad entre dos vectores no nulos en un espacio vectorial. Se calcula como el coseno del ángulo entre los dos vectores.

En el gráfico, los dos vectores se representan como flechas que parten del origen. El ángulo entre ellos es el formado por estas dos flechas.

**Interpretación del resultado:**

* **Similitud por coseno = 1:** Los vectores son idénticos y apuntan en la misma dirección.
* **Similitud por coseno = -1:** Los vectores son opuestos y apuntan en direcciones opuestas.
* **Similitud por coseno = 0:** Los vectores son ortogonales (perpendiculares).

**Cuanto más cercano esté el valor de la similitud por coseno a 1, más similares son los vectores.**
"""

print("En este ejemplo, la similitud por coseno es:", cosine_sim)

"""Volviendo ahora a nuestro caso de estudio con libros, calcularemos la similitud de coseno de la matriz `count_matrix` consigo misma, lo que significa que se está calculando la similitud entre todos los pares vectores **multidimensionales** de la matriz, que representan a cada uno de los libros.

El cálculo se apoya en una operación algebraica, efectuando el coseno como la siguiente operación entre matrices:

$cosine(x,y) = \frac{x. y^\intercal}{||x||.||y||} $
"""

cosine_sim = cosine_similarity(count_matrix, count_matrix)

"""Preparemos ahora un mapeo para obtener fácilmente el el índice de un libro a partir de su título:"""

indices = pd.Series(books.index, index=books['title'])
titles = books['title']

indices

"""Implementemos ahora el motor de recomendaciones a través de una función que, a partir de un título, nos entregue una cantidad dada de libros, que registren la más alta similitud por coseno con el argumento recibido."""

def get_recommendations(title, n=10, self_exclude = True):
    try:
        # Se intenta obtener el índice del título dado
        idx = indices[title]
    except KeyError:
        # Si el título no existe, se procede a encontrar el índice del libro más similar
        sim_scores = list(enumerate(cosine_sim))
        idx = max(sim_scores, key=lambda x: max(x[1]))[0]  # Índice del libro más similar

    # Se buscan las puntuaciones de similitud para el libro dado
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    if self_exclude :
      sim_scores = sim_scores[1:n+1]
    else :
      sim_scores = sim_scores[0:n+1]
    book_indices = [i[0] for i in sim_scores]
    scores = [i[1] for i in sim_scores]  # Se extraen los sim_scores

    # Se crea un DataFrame que integre los libros recomendados y sus sim_scores
    recommended_books = books.iloc[book_indices].copy()
    recommended_books['sim_score'] = scores

    return recommended_books

"""Probemos el recomendador:"""

get_recommendations("The Godfather", 5).transpose()

"""Ahora probemos lo mismo, incluyendo el propio libro"""

get_recommendations("The Godfather", 5, False).transpose()

"""> **PREGUNTA: ¿qué estrategia se podría seguir en caso de querer recomendaciones considerando *k* libros?**

## Recomendador híbrido

![](https://www.toonpool.com/user/250/files/hybrid_20095.jpg)

Sobre la función de recomendación se pueden seguir probando e implementando tantas ideas como se desee, incluso integrando distintas metodologías. Por ejemplo, se puede evaluar a partir de una combinación de *similitud por coseno* y *rating promedio*, o *similitud por coseno* y *rating ponderado*.
"""

def get_recommendations_hybrid(title, n=10, self_exclude=True):
    try:
        # Se intenta obtener el índice del título dado
        idx = indices[title]
    except KeyError:
        # Si el título no existe, se procede a encontrar el índice del libro más similar
        sim_scores = list(enumerate(cosine_sim))
        idx = max(sim_scores, key=lambda x: max(x[1]))[0]  # Índice del libro más similar

    # Se buscan las puntuaciones de similitud para el libro dado
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    if self_exclude:
        sim_scores = sim_scores[1:n+1]
    else:
        sim_scores = sim_scores[0:n+1]

    book_indices = [i[0] for i in sim_scores]
    cosine_similarities = [i[1] for i in sim_scores]

    # Se calcula la nueva métrica
    rating = books['average_rating'].iloc[book_indices].values
    hybrid_scores = [cosine_sim * rating for cosine_sim, rating in zip(cosine_similarities, rating)]
    scores = [i[1] for i in sim_scores]

    # Se crea un DataFrame que integre los libros recomendados y sus scores híbridos
    recommended_books = books.iloc[book_indices].copy()
    recommended_books['sim_score'] = scores
    recommended_books['hybrid_score'] = hybrid_scores

    # Se ordenaa por la nueva métrica en orden descendente
    recommended_books.sort_values('hybrid_score', ascending=False, inplace=True)

    return recommended_books

get_recommendations_hybrid("The Godfather", 5, True).transpose()

"""Así como implementamos la nueva métrica híbrida utlizando el *rating promedio*, podríamos haber utilizado el *rating ponderado* de IMDb.

## Filtrado colaborativo (Collaborative Filtering)

Simplemente a modo de conclusión, podemos decir que nuestro motor basado en contenido tiene algunas limitaciones. Sólo es capaz de sugerir libros que están *cercanos* a otro. Es decir, no es capaz de capturar gustos individuales y brindar recomendaciones entre géneros. Cualquiera que consulte nuestro motor a partir de un libro recibirá las mismas recomendaciones, independientemente de quién sea.

Estas limitaciones las aborda la estrategia de **filtrado colaborativo**, que se basa en la idea de que los usuarios similares a mí pueden usarse para predecir cuánto me gustará un producto o servicio en particular que esos usuarios han usado/experimentado, pero yo no.

![](https://miro.medium.com/max/706/1*DYJ-HQnOVvmm5suNtqV3Jw.png)

Existen dos formas de filtrado colaborativo:

![](https://miro.medium.com/max/1280/1*QvhetbRjCr1vryTch_2HZQ.jpeg)

- **User-based**, mide la similitud entre usuarios.
- **Item-based**, mide la similitud entre items.

Para poder abordar estrategias de este estilo, es necesario contar una base de datos con los consumos, gustos, *wishlists* o interacciones de los usuarios.
"""